{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather file - gap filling and formatting\n",
    "- Main tasks: \n",
    "    1. gap fill weather file\n",
    "    2. combine met and solrad info into single files for each site-year\n",
    "    3. address timezone issue\n",
    "    4. format weather file into MAIZSIM-readable format\n",
    "- Data source: \n",
    "    1. weadata/**temp_all.csv**\n",
    "    2. weadata/**rh_all.csv**\n",
    "    3. weadata/**precip_all.csv**\n",
    "    4. weadata/**solrad_all.csv**\n",
    "- Main output: \n",
    "    - weadata/data/control/**site_year.txt** - weather file for all site-years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import xarray as xr\n",
    "import datetime\n",
    "import time \n",
    "from timezonefinder import TimezoneFinder\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Reading in temperature, precip, RH & solar radiation data:\n",
    "- Main input:\n",
    "    - /weadata/**temp_all.csv**\n",
    "    - /weadata/**rh_all.csv**\n",
    "    - /weadata/**precip_all.csv**\n",
    "    - /weadata/**solrad_all.csv**\n",
    "- Main output: \n",
    "    - **df_temp, df_rh, df_precip, df_solrad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(197310, 237)\n",
      "(197310, 237)\n",
      "(197310, 237)\n",
      "(197310, 237)\n"
     ]
    }
   ],
   "source": [
    "# reading in compiled met & solrad data from weafile_read\n",
    "df_temp = pd.read_csv('/home/disk/eos8/ach315/upscale/weadata/temp_all.csv', index_col=0)\n",
    "df_rh = pd.read_csv('/home/disk/eos8/ach315/upscale/weadata/rh_all.csv', index_col=0)\n",
    "df_precip = pd.read_csv('/home/disk/eos8/ach315/upscale/weadata/precip_all.csv', index_col=0)\n",
    "df_solrad = pd.read_csv('/home/disk/eos8/ach315/upscale/weadata/backup/solrad_all.csv', index_col=0)\n",
    "\n",
    "# processing solar radiation data to only include growing season\n",
    "df_solrad = df_solrad.reindex(df_temp.index)\n",
    "\n",
    "# checking that all met elements aligned - dataframe shape should match\n",
    "print(df_temp.shape)\n",
    "print(df_rh.shape)\n",
    "print(df_precip.shape)\n",
    "print(df_solrad.shape)\n",
    "\n",
    "# saving the updated solar radiation data\n",
    "#df_solrad.to_csv('/home/disk/eos8/ach315/upscale/weadata/solrad_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Figure out valid site-years that can be gap-filled\n",
    "Selecting for site-years based on **crit_hrs** - consecutive missing hours of datapoints within raw data\n",
    "- Main input: **df_temp, df_precip, df_solrad**\n",
    "- Main output: **finalist**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input variables for loop\n",
    "datasets = list([df_temp, df_precip, df_solrad]) # weather datasets to process\n",
    "                                                 # df_rh is based off df_temp, so no need to evaluate \n",
    "\n",
    "finalist = list([[], [], []]) # final lists to store processed output\n",
    "                              # order: [0]-temp, [1]-precip, [2]-solrad\n",
    "\n",
    "years = np.arange(1961, 1991) # years\n",
    "\n",
    "growseason_start = '-04-01 00:00:00' # setting up growing season# \n",
    "growseason_end = '-10-31 23:00:00' # *** maybe want to change this to earlier, -03-01 00:00:00\n",
    "\n",
    "crit_hrs = 1 # critical hrs of missing data\n",
    "\n",
    "\n",
    "# loop through temp, precip & solrad dataset to pick out usable site-years\n",
    "for i in np.arange(len(datasets)):\n",
    "    dataset = datasets[i]\n",
    "    siteyears_all = list()\n",
    "    sites = dataset.columns\n",
    "    \n",
    "    for j in years:\n",
    "        start_time = str(j) + growseason_start\n",
    "        end_time = str(j) + growseason_end\n",
    "        siteyears = list()\n",
    "        \n",
    "        for k in sites:\n",
    "            df = dataset.loc[start_time:end_time, k] \n",
    "            df = pd.DataFrame(df)\n",
    "            df['group'] = df.notnull().astype(int) # df.notnull() returns TRUE or FALSE, \n",
    "                                                   # .astype(int) turns TRUE into 1, and FALSE into 0\n",
    "            df['group'] = df.group.cumsum() # calculating cumulative sum \n",
    "            df = df[df.iloc[:,0].isnull()] # selecting out individual timesteps that have missing data\n",
    "            df['count'] = df.groupby('group')['group'].transform('size') # counts the number of consecutive NANs \n",
    "            df = df.drop_duplicates('group')\n",
    "            \n",
    "            if df[df['count'] > crit_hrs].shape[0] == 0:\n",
    "                use_siteyear = str(j) + '_' + str(k)\n",
    "                siteyears.append(use_siteyear) # only record site-years that have fewer consecutive NANs than the critical value set\n",
    "        \n",
    "        siteyears_all.extend(siteyears)\n",
    "    \n",
    "    finalist[i] = siteyears_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Compare usable site-years for temp  & precip and find the common year-sites\n",
    "- Main intput: **finalist**\n",
    "- Main output: **yearsites**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp: 2838\n",
      "precip: 2254\n",
      "solrad: 7097\n",
      "overlapping siteyears: 2125\n"
     ]
    }
   ],
   "source": [
    "yearsites_temp = finalist[0]\n",
    "yearsites_rh = finalist[1]\n",
    "yearsites_precip = finalist[2]\n",
    "yearsites_solrad = finalist[3]\n",
    "\n",
    "print('temp:', len(yearsites_temp))\n",
    "print('precip:', len(yearsites_precip))\n",
    "print('solrad:', len(yearsites_solrad))\n",
    "\n",
    "yearsites = list(set(yearsites_temp) & set(yearsites_rh))\n",
    "yearsites = list(set(yearsites) & set(yearsites_precip))\n",
    "yearsites = list(set(yearsites) & set(yearsites_solrad))\n",
    "\n",
    "yearsites.sort()\n",
    "\n",
    "print('overlapping siteyears:', len(yearsites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crithrs_0 = len(yearsites)\n",
    "#crithrs_1 = len(yearsites)\n",
    "#crithrs_2 = len(yearsites)\n",
    "#crithrs_3 = len(yearsites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Visualization - available site-years vs. consecutive missing data hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 4 artists>"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0,1,2,3]\n",
    "width =  [crithrs_0, crithrs_1, crithrs_2, crithrs_3]\n",
    "plt.bar(x, width, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Sotre basic info of valid site-years\n",
    "- Main input: **yearsites**\n",
    "- Main output: \n",
    "    - weadata/**site_year_crithr1.csv** - site-year info for data filtered with crithr = 1\n",
    "    - weadata/**site_year.csv** - info on how many years of wea data each site has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the valid site-years?\n",
    "years = list()\n",
    "sites = list()\n",
    "\n",
    "for i in range(len(yearsites)):\n",
    "    year = yearsites[i][0:4]\n",
    "    years.append(year)\n",
    "    site = yearsites[i][5:10]\n",
    "    sites.append(site)\n",
    "\n",
    "df_yearsites = pd.DataFrame({'site': sites, 'year': years}, \n",
    "                            columns=['site', 'year'])\n",
    "df_yearsites = df_yearsites.sort_values(['site', 'year'])\n",
    "final_sites = list(set(df_yearsites.site))\n",
    "#df_yearsites.to_csv('../weadata/site_year_crithr1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many years of data does each site have?\n",
    "numofyears = list()\n",
    "\n",
    "for i in final_sites:\n",
    "    years = len(df_yearsites[df_yearsites[\"site\"] == i])\n",
    "    numofyears.append(years)\n",
    "    \n",
    "df_numofyears = pd.DataFrame({\"site\": final_sites, \"years\": numofyears})\n",
    "df_numofyears = df_numofyears.sort_values([\"site\"])\n",
    "df_numofyears = df_numofyears.reset_index().iloc[:, 1:3]\n",
    "#df_numofyears.to_csv(\"../weadata/site_years.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Compile and gap-fill usable site-years data into individual weather data files\n",
    "- Main tasks:\n",
    "    - figure out time zone for individual site and convet wea data from UTC into local time\n",
    "    - gap-fill wea data by linearly interpolating with data from hour before and after\n",
    "- Main input:\n",
    "    - /weadata/**site_info.csv** - city, state, lat, lon info for each site\n",
    "    - /weadata/**site_year_crithr1.csv** - site-year info for data filtered with crithr = 1\n",
    "    - df_temp, df_rh, df_precip, df_solrad\n",
    "- Main output:\n",
    "    - /weadata/data/control/**site_year.txt** - MAIZSIM weather file for every site-year\n",
    "- Functions:\n",
    "    - find_zone(site)\n",
    "    - utc_to_local(times, zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time zone finder\n",
    "def find_zone(site):\n",
    "    \"\"\"\n",
    "    find time zone for specific sites\n",
    "    \"\"\"\n",
    "    lat = float(siteinfo[siteinfo.site == site].lat)\n",
    "    lon = float(siteinfo[siteinfo.site == site].lon) * -1\n",
    "    tf = TimezoneFinder()    \n",
    "    zone = tf.timezone_at(lng=lon, lat=lat)\n",
    "    return zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utc conversion to local time\n",
    "def utc_to_local(times, zone):\n",
    "    \"\"\"\n",
    "    convert list of utc timestamps into local time\n",
    "    \"\"\"\n",
    "    times = times.to_pydatetime() # convert from pd.DatetimeIndex into python datetime format\n",
    "    utc = pytz.timezone('UTC') # setting up the UTC timezone, requires package 'pytz'\n",
    "    local_datetime = list()\n",
    "    \n",
    "    for time in times:\n",
    "        utctime = utc.localize(time) # adding UTC timezone to datetime\n",
    "        localtime = utctime.astimezone(pytz.timezone(zone)) \n",
    "        datetime = pd.to_datetime(localtime)\n",
    "        local_datetime.append(datetime)\n",
    "        \n",
    "    return local_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time # code block run time ~52 mins\n",
    "\n",
    "### setting up growing season period\n",
    "season_start, season_end = '04-01', '10-31'\n",
    "\n",
    "### reading in required files\n",
    "siteinfo = pd.read_csv('/home/disk/eos8/ach315/upscale/weadata/site_info.csv', dtype='str', usecols=[1,2,3,4,5])\n",
    "siteyear = pd.read_csv('/home/disk/eos8/ach315/upscale/weadata/site_year_crithr1.csv', dtype='str', usecols=[1,2])\n",
    "siteyear = siteyear[siteyear.site != '41415'] # dropping out Guam within dataset\n",
    "\n",
    "### starting the loop to process each site-year\n",
    "for i in np.arange(siteyear.shape[0]): \n",
    "    # selecting site-year combinations\n",
    "    site = siteyear.iloc[i,0]\n",
    "    year = siteyear.iloc[i,1]\n",
    "    print(site, year)\n",
    "    \n",
    "    # constructing dataframe that will hold all weather data\n",
    "    col = ['jday','date','hour','solrad','temp','precip','rh', 'co2']\n",
    "    df_wea = pd.DataFrame(columns=col)\n",
    "\n",
    "    # setting up for time-relating entries\n",
    "    times = pd.date_range(season_start + '-' + str(year), \n",
    "                          season_end + '-' + str(year)+ ' 23:00:00', freq='1H') # utc time\n",
    "    zone = find_zone(site)\n",
    "    local_datetime = utc_to_local(times, zone)\n",
    "            \n",
    "    # selecting weather data\n",
    "    utc_start, utc_end = str(times[0]), str(times[-1])\n",
    "    df_wea.temp = list(df_temp[utc_start:utc_end][site])\n",
    "    df_wea.rh = list(np.round((df_rh[utc_start:utc_end][site])*100, 2))\n",
    "    df_wea.precip = list(df_precip[utc_start:utc_end][site]/10) #*** this is a temporary fix for precip scaling bug\n",
    "    df_wea.co2 = 400    \n",
    "\n",
    "    # selecting solar radiation \n",
    "    t1 = pd.to_datetime(utc_start).to_pydatetime()\n",
    "    t2 = pd.to_datetime(utc_end).to_pydatetime()\n",
    "    tdiff = t2-t1\n",
    "    local_start = str(local_datetime[0])[:19] \n",
    "    local_end = str(pd.to_datetime(local_start).to_pydatetime() + tdiff)[:19]\n",
    "    df_wea.solrad = list(df_solrad[local_start:local_end][site])\n",
    "\n",
    "    # adding time-relating info to data frame\n",
    "    local = pd.date_range(local_start, local_end, freq='H')\n",
    "    df_wea.jday = local.dayofyear\n",
    "    df_wea.date = local.strftime(\"'%m/%d/%Y'\")\n",
    "    df_wea.hour = local.hour    \n",
    "    \n",
    "    # gap-filling weather data\n",
    "    if df_wea.isna().sum().sum() > 0:\n",
    "        # creating a log file that documents the number of missing data for each site-year\n",
    "        f = open('/home/disk/eos8/ach315/upscale/weadata/data/log.txt', 'a+')\n",
    "        f.write('site: %s' %siteyear.iloc[i,:][0])\n",
    "        f.write(', year: %s' %siteyear.iloc[i,:][1])\n",
    "        f.write(', gap-filled: %s\\r\\n' %df_wea.isna().sum().sum())\n",
    "        f.close()\n",
    "        \n",
    "        # gap-filling data by linearly interpolating with data from hour before and after\n",
    "        df_wea = df_wea.interpolate() \n",
    "        \n",
    "    # saving individual site-year weather file into .csv \n",
    "#    df_wea.to_csv('/home/disk/eos8/ach315/upscale/weadata/data/control/' + site + '_' + year + '.txt', sep='\\t', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Final step of gap-filling if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since pd.interpolate() cannot gap-fill missing data if the missing data is located at the very beginning of the data (nan in first row), the code checks whether there are site-years with that situation, and if so assigns the missing data in the first row a default number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1354,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob.glob('/home/disk/eos8/ach315/upscale/weadata/data/control/*')\n",
    "\n",
    "for name in fnames: \n",
    "    df_wea = pd.read_csv(name)\n",
    "    df_wea = df_wea.drop(df_wea.columns[0], axis=1)\n",
    "    if df_wea.isna().sum().sum() > 0:\n",
    "        print(name.split('/')[-1], df_wea.isna().sum().sum())\n",
    "\n",
    "# no files required additional gap-filling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: reading in a final compiled weather file to check output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jday</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>solrad</th>\n",
       "      <th>temp</th>\n",
       "      <th>precip</th>\n",
       "      <th>rh</th>\n",
       "      <th>co2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>'03/31/1989'</td>\n",
       "      <td>17</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.18</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>'03/31/1989'</td>\n",
       "      <td>18</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>85.04</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>'03/31/1989'</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>88.77</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>'03/31/1989'</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.69</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>'03/31/1989'</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.13</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   jday          date  hour  solrad  temp  precip     rh  co2\n",
       "0    90  '03/31/1989'    17    29.0   7.8     0.0  76.18  400\n",
       "1    90  '03/31/1989'    18     4.0   5.6     1.3  85.04  400\n",
       "2    90  '03/31/1989'    19     0.0   6.1     2.5  88.77  400\n",
       "3    90  '03/31/1989'    20     0.0   6.1     0.0  85.69  400\n",
       "4    90  '03/31/1989'    21     0.0   6.1     0.0  82.13  400"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('/home/disk/eos8/ach315/upscale/weadata/data/control/24127_1989.txt', sep='\\t')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step *. Select for subset dataset to include only valid (can be gap-filled) weather data\n",
    "**** JH 200506- thinking about whehter to keep this or not ****\n",
    "- Main task:\n",
    "- Main input: \n",
    "    - /weadata/**site_year_crithr1.csv**\n",
    "    - /weadata/**temp_all.csv**\n",
    "    - /weadata/**precip_all.csv**\n",
    "    - /weadata/**rh_all.csv**\n",
    "    - /weadata/**solrad_all.csv**\n",
    "- Main output: **/weadata/weadata.csv** - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total site-years: 2125\n"
     ]
    }
   ],
   "source": [
    "# reading in data\n",
    "siteyear = pd.read_csv('/home/disk/eos8/ach315/upscale/weadata/site_year_crithr1.csv', dtype=\"str\")\n",
    "siteyear = siteyear.drop(siteyear.columns[0], axis=1)\n",
    "print('total site-years:', siteyear.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 190923: still thinking whether the code below in this step 5 section is necessary now\n",
    "# Read in individual weather data files and merge them into long form data frame:\n",
    "\n",
    "filelist = ['temp_all.csv', 'precip_all.csv', 'rh_all.csv', 'solrad_all.csv']\n",
    "weavars = ['temp', 'precip', 'rh', 'solrad']\n",
    "filenums = len(filelist)\n",
    "dfs = [[],[],[],[]]\n",
    "sites = sorted(list(set(siteyear.site)))\n",
    "grow_months = [5,6,7,8,9,10]\n",
    "\n",
    "for i in range(filenums):\n",
    "    dfs[i] = pd.read_csv('/home/disk/eos8/ach315/upscale/weadata/' + filelist[i], index_col=0)\n",
    "    dfs[i].index = pd.to_datetime(dfs[i].index) # converting index timepoint into datetimeindex\n",
    "    dfs[i] = dfs[i][dfs[i].index.month.isin(grow_months)] # selecting only the growing season timepoints\n",
    "    dfs[i] = dfs[i].filter(items=sites, axis=1) # selcting only the valid sites\n",
    "    dfs[i][\"date\"] = dfs[i].index # creating another column that stores datetimeindex info, for melting purpose\n",
    "    dfs[i] = pd.melt(dfs[i], id_vars=\"date\", var_name=\"sites\", value_name=weavars[i])\n",
    "\n",
    "df = pd.merge(dfs[0], dfs[1])\n",
    "df = pd.merge(df, dfs[2])\n",
    "df = pd.merge(df, dfs[3])    \n",
    "\n",
    "df.index = pd.to_datetime(df.date)\n",
    "df = df.iloc[:, 1:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting for valid site-years\n",
    "valid_siteyears = siteyear.shape[0]\n",
    "frames = []\n",
    "\n",
    "for i in range(valid_siteyears):\n",
    "    dfi = df[df.index.year == int(siteyear.year[i])]\n",
    "    dfi = dfi[dfi.sites == siteyear.site[i]]\n",
    "    frames.append(dfi)\n",
    "#    print(len(frames)) # since this code takes time to run, \n",
    "                       # this helps to see where in the process it is\n",
    "\n",
    "df_valid = pd.concat(frames)\n",
    "# saving all valid weather dataframe into .csv\n",
    "#df_valid.to_csv(\"/home/disk/eos8/ach315/upscale/weadata/weadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sites</th>\n",
       "      <th>temp</th>\n",
       "      <th>precip</th>\n",
       "      <th>rh</th>\n",
       "      <th>solrad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1964-05-01 00:00:00</th>\n",
       "      <td>3103</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.605071</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964-05-01 01:00:00</th>\n",
       "      <td>3103</td>\n",
       "      <td>5.6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.850413</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964-05-01 02:00:00</th>\n",
       "      <td>3103</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.925122</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964-05-01 03:00:00</th>\n",
       "      <td>3103</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.924547</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964-05-01 04:00:00</th>\n",
       "      <td>3103</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.924283</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sites  temp  precip        rh  solrad\n",
       "date                                                      \n",
       "1964-05-01 00:00:00   3103   9.4     0.0  0.605071     0.0\n",
       "1964-05-01 01:00:00   3103   5.6    15.0  0.850413     0.0\n",
       "1964-05-01 02:00:00   3103   4.4     0.0  0.925122     0.0\n",
       "1964-05-01 03:00:00   3103   3.3     0.0  0.924547     0.0\n",
       "1964-05-01 04:00:00   3103   2.8     0.0  0.924283     0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('/home/disk/eos8/ach315/upscale/weadata/weadata.csv', index_col=0)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
