{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in USAF site information - from solar radiation dataset\n",
    "df_sites = pd.read_csv('/home/disk/eos8/ach315/upscale/weadata/stations_info_9110.csv')\n",
    "df_sites.head()\n",
    "\n",
    "# select only class 1 stations (see NSRDB manual p.7-8 for more details)\n",
    "df_class1 = df_sites[(df_sites['CLASS'] == 1)]\n",
    "sites_class1 = list(df_class1.USAF) # station list with class 1 quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# timing related settings\n",
    "years = np.arange(1991, 2011) # timeframe in which we have weather data\n",
    "dateparse = lambda dates: [datetime.datetime.strptime(d, \"%Y%m%d%H\") for d in dates] # dateparsing method to be used in pd.read_fwf\n",
    "season_start, season_end = '03-01-', '11-30-' # setting a pretty borad range for growing season\n",
    "\n",
    "# setting up np.read_fwf arguments\n",
    "colnames = ['time', 'temp', 'temp_quality', 'dew_temp', 'dtemp_quality', 'precip', \n",
    "            'precip_time', 'precip_depth', 'precip_quality', 'precip_perhr', 'rh']\n",
    "colspecs = [(15,25), (87,92), (92,93), (93,98), (98,99), (105,8193)]\n",
    "\n",
    "# empty dataframes to store data from all site-years\n",
    "df_temp_all = pd.DataFrame()\n",
    "df_rh_all = pd.DataFrame()\n",
    "df_precip_all = pd.DataFrame()\n",
    "\n",
    "# reading in all weather data and storing as dataframe\n",
    "for year in years:\n",
    "    print(year) # output to track code progress\n",
    "    times = pd.date_range(season_start + str(year), season_end + str(year) + ' 23:00:00', freq='1H')\n",
    "    \n",
    "    # creating dataframes to store all site data for an individual year\n",
    "    df_temp_sites = pd.DataFrame(index=times)\n",
    "    df_rh_sites = pd.DataFrame(index=times)\n",
    "    df_precip_sites = pd.DataFrame(index=times)\n",
    "    \n",
    "    for site in sites_class1:\n",
    "        # selecting for file associated with specified site\n",
    "        file = glob.glob('/home/disk/eos8/ach315/data/ISH/' + str(year) + '/' + str(site) + '-*')\n",
    "        \n",
    "        if len(file) == 0: # when specified site does not exist for current year\n",
    "            continue # skip the following code and move on to the next site in the for loop\n",
    "        elif len(file) == 1:\n",
    "            name = file[0]\n",
    "        else: # when specified USAF site has more than one WBAN ID, resulting in more than one unique site\n",
    "            print('choosing from multiple files: ', file)\n",
    "            name = glob.glob('/home/disk/eos8/ach315/data/ISH/' + str(year) + '/' + str(site) + '-99999-*')[0]\n",
    "            # for cases when a USAF station ID is linked to two WBAN IDs, select the one in which WBAN is listed as 99999\n",
    "            \n",
    "        # reading in raw weather data as fixed-width data format\n",
    "        df = pd.read_fwf(name, names=colnames, colspecs=colspecs, header=None, index_col='time',\n",
    "                         encoding='latin_1', dtype={'temp':int, 'precip':str}, \n",
    "                         parse_dates=True, date_parser=dateparse)\n",
    "        # remove duplicated hours, keeping only the first measurement per hour\n",
    "        df = df[df.index.duplicated(keep='first') == False]\n",
    "\n",
    "        # add in missing time values (corrects for leap years) and keeps only growing season\n",
    "        df = df.reindex(times, fill_value=np.nan)\n",
    "\n",
    "        # finding precip data\n",
    "        df.precip_time = df[df['precip'].str.find('ADDAA1')!=-1]['precip'].str.split('ADDAA1').str.get(1).str.slice(0,2).astype(float)\n",
    "        df.precip_depth = df[df['precip'].str.find('ADDAA1')!=-1]['precip'].str.split('ADDAA1').str.get(1).str.slice(2, 6).astype(float)\n",
    "        df.precip_quality = df[df['precip'].str.find('ADDAA1')!=-1]['precip'].str.split('ADDAA1').str.get(1).str.slice(7,8)\n",
    "                \n",
    "        # filtering out weather data based on quality code (data manual p.26)\n",
    "        # removing data with code 3 (Erroneous) or 7 (Erroneous, data originate from an NCEI data source)\n",
    "        # - temp\n",
    "        quality_temp = (df.temp_quality=='3') | (df.temp_quality=='7')\n",
    "        rows_temp = df[quality_temp].index\n",
    "        df.loc[rows_temp, 'temp'] = np.nan\n",
    "        # - dew temp\n",
    "        quality_dtemp = (df.dtemp_quality=='3') | (df.dtemp_quality=='7')\n",
    "        rows_dtemp = df[quality_dtemp].index\n",
    "        df.loc[rows_dtemp, 'dew_temp'] = np.nan\n",
    "        # - precip\n",
    "        quality_precip = (df.precip_quality=='3') | (df.precip_quality=='7')\n",
    "        rows_precip = df[quality_precip].index\n",
    "        df.loc[rows_precip, 'precip'] = np.nan\n",
    "\n",
    "        # replacing missing values with NANs                    \n",
    "        df.temp = df.temp.replace({9999: np.nan})\n",
    "        df.dew_temp = df.dew_temp.replace({9999: np.nan})\n",
    "        df.precip_time = df.precip_time.replace({99: np.nan})\n",
    "        df.precip_depth = df.precip_depth.replace({9999: np.nan})\n",
    "\n",
    "        # calculating hourly precip depth\n",
    "        df.precip_perhr = df.precip_depth/df.precip_time\n",
    "        df.precip_perhr = df.precip_perhr.replace({np.inf: np.nan}) # accounting for cases where precip_hr = 0\n",
    "                                                                    # which produces infinite precip_perhr\n",
    "\n",
    "        # converting units \n",
    "        df.temp = df.temp/10\n",
    "        df.dew_temp = df.dew_temp/10\n",
    "        df.precip_perhr = df.precip_perhr/10\n",
    "\n",
    "        # calculating RH through Clausius Clapeyron\n",
    "        df.rh = CC(df.temp, df.dew_temp)*100\n",
    "        if df[df.rh>100].rh.sum() > 100:\n",
    "            print(site, year)\n",
    "\n",
    "        # combining weather data into individual dataframes\n",
    "        df_temp = pd.DataFrame({site: df.temp}, index= times)\n",
    "        df_rh = pd.DataFrame({site: df.rh}, index=times)\n",
    "        df_precip = pd.DataFrame({site: df.precip_perhr}, index=times)\n",
    "\n",
    "        df_temp_sites = pd.concat([df_temp_sites, df_temp], axis= 1, sort=True)\n",
    "        df_rh_sites = pd.concat([df_rh_sites, df_rh], axis=1, sort=True)\n",
    "        df_precip_sites = pd.concat([df_precip_sites, df_precip], axis=1, sort=True)       \n",
    "\n",
    "    # combining all site-years data together\n",
    "    df_temp_all = pd.concat([df_temp_all, df_temp_sites], sort=True)\n",
    "    df_rh_all = pd.concat([df_rh_all, df_rh_sites], sort=True)\n",
    "    df_precip_all = pd.concat([df_precip_all, df_precip_sites], sort=True)\n",
    "\n",
    "#df_temp_all.to_csv('/home/disk/eos8/ach315/upscale/weadata/temp_9110_class1.csv')\n",
    "#df_precip_all.to_csv('/home/disk/eos8/ach315/upscale/weadata/precip_9110_class1.csv')\n",
    "#df_rh_all.to_csv('/home/disk/eos8/ach315/upscale/weadata/rh_9110_class1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ideotype]",
   "language": "python",
   "name": "conda-env-ideotype-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
