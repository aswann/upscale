{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating GDD to estimate planting date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import datetime\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1961-1990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "CPU times: user 12min 48s, sys: 13.3 s, total: 13min 2s\n",
      "Wall time: 14min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# timing related settings\n",
    "years = np.arange(1961, 1991) # timeframe in which we have weather data\n",
    "dateparse = lambda dates: [datetime.datetime.strptime(d, \"%Y%m%d%H\") for d in dates] # dateparsing method to be used in pd.read_fwf\n",
    "season_start, season_end = '02-01-', '6-30-' # setting a pretty borad range for growing season\n",
    "\n",
    "# setting up np.read_fwf arguments\n",
    "colnames = ['time', 'temp', 'temp_quality']\n",
    "colspecs = [(15,25), (87,92), (92,93)]\n",
    "\n",
    "# empty dataframes to store data from all site-years\n",
    "df_temp_all = pd.DataFrame()\n",
    "\n",
    "# reading in all weather data and storing as dataframe\n",
    "for year in years:\n",
    "    print(year) # output to track code progress\n",
    "    times = pd.date_range(season_start + str(year), season_end + str(year) + ' 23:00:00', freq='1H')\n",
    "    fnames = glob.glob('/home/disk/eos8/ach315/data/ISH/' + str(year) + '/*')\n",
    "    \n",
    "    # creating dataframes to store all site data for an individual year\n",
    "    df_temp_sites = pd.DataFrame(index=times)\n",
    "    \n",
    "    for name in fnames:\n",
    "        # WBAN site name \n",
    "        site_id = name.split('/')[-1].split('-')[-2]\n",
    "        \n",
    "        # read in individual files\n",
    "        df = pd.read_fwf(name, names=colnames, colspecs=colspecs, header=None, index_col='time',\n",
    "                         encoding='latin_1', dtype={'temp':int, 'precip':str}, \n",
    "                         parse_dates=True, date_parser=dateparse)\n",
    "    \n",
    "        # remove duplicated hours, keeping only the first measurement per hour\n",
    "        df = df[df.index.duplicated(keep='first') == False]\n",
    "        \n",
    "        # add in missing time values (corrects for leap years) and keeps only growing season\n",
    "        df = df.reindex(times, fill_value=np.nan)\n",
    "                    \n",
    "        # filtering out weather data based on quality code (data manual p.26)\n",
    "        # removing data with code 3 (Erroneous) or 7 (Erroneous, data originate from an NCEI data source)\n",
    "        # - temp\n",
    "        quality_temp = (df.temp_quality=='3') | (df.temp_quality=='7')\n",
    "        rows_temp = df[quality_temp].index\n",
    "        df.loc[rows_temp, 'temp'] = np.nan\n",
    "\n",
    "        # replacing missing data with NaN\n",
    "        df.temp = df.temp.replace({9999: np.nan})\n",
    "        \n",
    "        # converting units \n",
    "        df.temp = df.temp/10\n",
    "        \n",
    "        # combining weather data into individual dataframes\n",
    "        df_temp = pd.DataFrame({site_id: df.temp}, index= times)\n",
    "        df_temp_sites = pd.concat([df_temp_sites, df_temp], axis= 1, sort=True)\n",
    "\n",
    "    # combining all site-years data together\n",
    "    df_temp_all = pd.concat([df_temp_all, df_temp_sites], sort=True)\n",
    "\n",
    "#df_temp_all.to_csv('/home/disk/eos8/ach315/upscale/weadata/temp_6190_gdd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1991-2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in USAF site information - from solar radiation dataset\n",
    "df_sites = pd.read_csv('/home/disk/eos8/ach315/upscale/weadata/stations_info_9110.csv')\n",
    "df_sites.head()\n",
    "\n",
    "# select only class 1 stations (see NSRDB manual p.7-8 for more details)\n",
    "df_class1 = df_sites[(df_sites['CLASS'] == 1)]\n",
    "sites_class1 = list(df_class1.USAF) # station list with class 1 quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "choosing from multiple files:  ['/home/disk/eos8/ach315/data/ISH/2000/724665-93010-2000', '/home/disk/eos8/ach315/data/ISH/2000/724665-99999-2000']\n",
      "2001\n",
      "choosing from multiple files:  ['/home/disk/eos8/ach315/data/ISH/2001/724665-93010-2001', '/home/disk/eos8/ach315/data/ISH/2001/724665-99999-2001']\n",
      "2002\n",
      "choosing from multiple files:  ['/home/disk/eos8/ach315/data/ISH/2002/724665-99999-2002', '/home/disk/eos8/ach315/data/ISH/2002/724665-93010-2002']\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "choosing from multiple files:  ['/home/disk/eos8/ach315/data/ISH/2010/722045-12843-2010', '/home/disk/eos8/ach315/data/ISH/2010/722045-99999-2010']\n",
      "choosing from multiple files:  ['/home/disk/eos8/ach315/data/ISH/2010/722146-12816-2010', '/home/disk/eos8/ach315/data/ISH/2010/722146-99999-2010']\n",
      "choosing from multiple files:  ['/home/disk/eos8/ach315/data/ISH/2010/723183-13877-2010', '/home/disk/eos8/ach315/data/ISH/2010/723183-99999-2010']\n",
      "choosing from multiple files:  ['/home/disk/eos8/ach315/data/ISH/2010/724089-13781-2010', '/home/disk/eos8/ach315/data/ISH/2010/724089-99999-2010']\n",
      "choosing from multiple files:  ['/home/disk/eos8/ach315/data/ISH/2010/724236-03889-2010', '/home/disk/eos8/ach315/data/ISH/2010/724236-99999-2010']\n",
      "choosing from multiple files:  ['/home/disk/eos8/ach315/data/ISH/2010/725035-04781-2010', '/home/disk/eos8/ach315/data/ISH/2010/725035-99999-2010']\n",
      "choosing from multiple files:  ['/home/disk/eos8/ach315/data/ISH/2010/725095-94746-2010', '/home/disk/eos8/ach315/data/ISH/2010/725095-99999-2010']\n",
      "choosing from multiple files:  ['/home/disk/eos8/ach315/data/ISH/2010/725115-14711-2010', '/home/disk/eos8/ach315/data/ISH/2010/725115-99999-2010']\n",
      "choosing from multiple files:  ['/home/disk/eos8/ach315/data/ISH/2010/725246-14891-2010', '/home/disk/eos8/ach315/data/ISH/2010/725246-99999-2010']\n",
      "CPU times: user 17min 29s, sys: 14.4 s, total: 17min 43s\n",
      "Wall time: 19min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# timing related settings\n",
    "years = np.arange(1991, 2011) # timeframe in which we have weather data\n",
    "dateparse = lambda dates: [datetime.datetime.strptime(d, \"%Y%m%d%H\") for d in dates] # dateparsing method to be used in pd.read_fwf\n",
    "season_start, season_end = '02-01-', '6-30-' # setting a pretty borad range for growing season\n",
    "\n",
    "# setting up np.read_fwf arguments\n",
    "colnames = ['time', 'temp', 'temp_quality']\n",
    "colspecs = [(15,25), (87,92), (92,93)]\n",
    "\n",
    "# empty dataframes to store data from all site-years\n",
    "df_temp_all = pd.DataFrame()\n",
    "\n",
    "# reading in all weather data and storing as dataframe\n",
    "for year in years:\n",
    "    print(year) # output to track code progress\n",
    "    times = pd.date_range(season_start + str(year), season_end + str(year) + ' 23:00:00', freq='1H')\n",
    "    \n",
    "    # creating dataframes to store all site data for an individual year\n",
    "    df_temp_sites = pd.DataFrame(index=times)\n",
    "    \n",
    "    for site in sites_class1:\n",
    "        # selecting for file associated with specified site\n",
    "        file = glob.glob('/home/disk/eos8/ach315/data/ISH/' + str(year) + '/' + str(site) + '-*')\n",
    "        \n",
    "        if len(file) == 0: # when specified site does not exist for current year\n",
    "            continue # skip the following code and move on to the next site in the for loop\n",
    "        elif len(file) == 1:\n",
    "            name = file[0]\n",
    "        else: # when specified USAF site has more than one WBAN ID, resulting in more than one unique site\n",
    "            print('choosing from multiple files: ', file)\n",
    "            name = glob.glob('/home/disk/eos8/ach315/data/ISH/' + str(year) + '/' + str(site) + '-99999-*')[0]\n",
    "            # for cases when a USAF station ID is linked to two WBAN IDs, select the one in which WBAN is listed as 99999\n",
    "            \n",
    "        # reading in raw weather data as fixed-width data format\n",
    "        df = pd.read_fwf(name, names=colnames, colspecs=colspecs, header=None, index_col='time',\n",
    "                         encoding='latin_1', dtype={'temp':int, 'precip':str}, \n",
    "                         parse_dates=True, date_parser=dateparse)\n",
    "        # remove duplicated hours, keeping only the first measurement per hour\n",
    "        df = df[df.index.duplicated(keep='first') == False]\n",
    "\n",
    "        # add in missing time values (corrects for leap years) and keeps only growing season\n",
    "        df = df.reindex(times, fill_value=np.nan)\n",
    "                \n",
    "        # filtering out weather data based on quality code (data manual p.26)\n",
    "        # removing data with code 3 (Erroneous) or 7 (Erroneous, data originate from an NCEI data source)\n",
    "        # - temp\n",
    "        quality_temp = (df.temp_quality=='3') | (df.temp_quality=='7')\n",
    "        rows_temp = df[quality_temp].index\n",
    "        df.loc[rows_temp, 'temp'] = np.nan\n",
    "\n",
    "        # replacing missing values with NANs                    \n",
    "        df.temp = df.temp.replace({9999: np.nan})\n",
    "\n",
    "        # converting units \n",
    "        df.temp = df.temp/10\n",
    "\n",
    "        # combining weather data into individual dataframes\n",
    "        df_temp = pd.DataFrame({site: df.temp}, index= times)\n",
    "        df_temp_sites = pd.concat([df_temp_sites, df_temp], axis= 1, sort=True)\n",
    "\n",
    "    # combining all site-years data together\n",
    "    df_temp_all = pd.concat([df_temp_all, df_temp_sites], sort=True)\n",
    "\n",
    "#df_temp_all.to_csv('/home/disk/eos8/ach315/upscale/weadata/temp_9110_gdd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge two temp datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1961-1990:  (108168, 237)\n",
      "1991-2010:  (72120, 241)\n",
      "1961-2010:  (180288, 274)\n"
     ]
    }
   ],
   "source": [
    "# read in weather data 1961-1990\n",
    "df_temp_6190 = pd.read_csv('/home/disk/eos8/ach315/upscale/weadata/temp_6190_gdd.csv', index_col=0)\n",
    "# convert station ID header from WBAN to USAF (in order to make continuous with 1991-2010)\n",
    "df_stations = pd.read_csv('/home/disk/eos8/ach315/data/ISH_NSRD/stations_wban_usaf.csv', header=None, dtype='str')\n",
    "df_stations.columns = ['WBAN', 'USAF']\n",
    "sites_wban = list(df_temp_6190.columns)\n",
    "sites_usaf = df_stations[df_stations['WBAN'].isin(sites_wban)]['USAF']\n",
    "\n",
    "# assign new USAF headers\n",
    "df_temp_6190.columns = sites_usaf; df_temp_6190 = df_temp_6190.sort_index(axis=1)\n",
    "print('1961-1990: ', df_temp_6190.shape)\n",
    "\n",
    "# read in weather data 1991-2010\n",
    "df_temp_9110 = pd.read_csv('/home/disk/eos8/ach315/upscale/weadata/temp_9110_gdd.csv', index_col=0)\n",
    "print('1991-2010: ', df_temp_9110.shape)\n",
    "\n",
    "# stitch two time periods together\n",
    "df_temp = pd.concat([df_temp_6190, df_temp_9110], axis=0, join='outer'); df_temp = df_temp.sort_index(axis=1)\n",
    "print('1961-2010: ', df_temp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select valid siteyears (based on growing season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior: 4225\n",
      "filtered: 3300\n"
     ]
    }
   ],
   "source": [
    "# filter\n",
    "df_summary = pd.read_csv('/home/disk/eos8/ach315/upscale/weadata/site_summary.csv', \n",
    "                         index_col=0, dtype={'site':str})\n",
    "df_filtered = df_summary[(df_summary.area > 1000) & (df_summary.perct_irri < 50)] \n",
    "\n",
    "# how many site-years left?\n",
    "df_siteyears = pd.read_csv('/home/disk/eos8/ach315/upscale/weadata/siteyears_crithr2.csv', dtype='str', usecols=[1,2])\n",
    "siteyears_filtered = df_siteyears[df_siteyears.site.isin(df_filtered.site)]\n",
    "print('prior:', df_siteyears.shape[0])\n",
    "print('filtered:', siteyears_filtered.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>722060</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>722060</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>722060</td>\n",
       "      <td>1964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>722060</td>\n",
       "      <td>1965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>722060</td>\n",
       "      <td>1966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4130</th>\n",
       "      <td>727970</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4131</th>\n",
       "      <td>727970</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>727970</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>727970</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4134</th>\n",
       "      <td>727970</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        site  year\n",
       "179   722060  1961\n",
       "180   722060  1962\n",
       "181   722060  1964\n",
       "182   722060  1965\n",
       "183   722060  1966\n",
       "...      ...   ...\n",
       "4130  727970  1991\n",
       "4131  727970  1992\n",
       "4132  727970  1993\n",
       "4133  727970  1994\n",
       "4134  727970  1995\n",
       "\n",
       "[3300 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siteyears_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(df_temp['1961-02-01':'1961-06-30']['700260'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1991-02-01 00:00:00     8.9\n",
       "1991-02-01 01:00:00     8.9\n",
       "1991-02-01 02:00:00     8.9\n",
       "1991-02-01 03:00:00     8.3\n",
       "1991-02-01 04:00:00     8.3\n",
       "                       ... \n",
       "1991-06-29 19:00:00    12.8\n",
       "1991-06-29 20:00:00    12.8\n",
       "1991-06-29 21:00:00    15.0\n",
       "1991-06-29 22:00:00    13.9\n",
       "1991-06-29 23:00:00    14.4\n",
       "Name: 727970, Length: 3576, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp['1991-02-01':'1991-06-30']['727970']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_slice = pd.DataFrame(df_temp['1991-02-01':'1991-06-30']['727970']).interpolate()\n",
    "temps = list(df_temp_slice.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gdd(temps): \n",
    "\"\"\"\n",
    "- calculates GDH with base temperature = 8˚C\n",
    "- calculated values divided by 24 to correspond to daily values\n",
    "- function returns count of point in which gdd exceeds 100\n",
    "  which can then be used to identify date in which GDD=100 is reached\n",
    "\"\"\"\n",
    "    gdd = 0\n",
    "    for count, temp in enumerate(temps): \n",
    "        if gdd > 100: \n",
    "            break\n",
    "        else:\n",
    "            if temp-8 < 0:\n",
    "                gdd += 0\n",
    "            else:\n",
    "                gdd += (temp-8)/24\n",
    "    return(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1991-05-04\n"
     ]
    }
   ],
   "source": [
    "loc = calc_gdd(temps)\n",
    "pdate = list(df_temp_slice.index)[loc][:10]\n",
    "print(pdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ideotype]",
   "language": "python",
   "name": "conda-env-ideotype-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
