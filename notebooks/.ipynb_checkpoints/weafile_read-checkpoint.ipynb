{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the MAIZSIM weather file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "import time \n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in and processing met data (NASA ISH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: create function that calculates RH with temperature and dew point temperatureThis list is called: weafile_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Clausius-Clapeyron function\n",
    "\n",
    "def CC(temp, temp_dew):\n",
    "    \"\"\"\n",
    "    function that calculates relative humidity with temperature and dew point temperature\n",
    "    temperautre input units: ËšC\n",
    "    \"\"\"\n",
    "    # constant parameters\n",
    "    Tref = 273.15  # reference temperature\n",
    "    Es_Tref = 6.11 # saturation vapor pressure at reference temperature\n",
    "    Lv = 2.5e+06   # latent heat of vaporation (J/kg)\n",
    "    Rv = 461       # gas constant for moist air (J/kg)\n",
    "    \n",
    "    # transformed temperature inputs\n",
    "    Tair = temp + Tref\n",
    "    Tdew = temp_dew + Tref\n",
    "    \n",
    "    # Clausius-Clapeyron relation\n",
    "    es = Es_Tref*np.exp((Lv/Rv)*(1/Tref - 1/Tair))\n",
    "    e = Es_Tref*np.exp((Lv/Rv)*(1/Tref - 1/Tdew))\n",
    "    rh = round(e/es,4)\n",
    "    \n",
    "    return(rh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: read in individual site-year the weather files and parse out data needed\n",
    "Need to parce out relevant info, and store the relevant weather data into individual pd.DataArrays.\n",
    "The relevant weather data include:\n",
    "- date/time: need to convert into datetime 64 format\n",
    "- temperature\n",
    "- dew temperature\n",
    "- RH\n",
    "- precipitaiton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1973 /home/disk/eos8/ach315/data/ISH/1973/725330-14827-1973\n",
      "1973 /home/disk/eos8/ach315/data/ISH/1973/723530-13967-1973\n",
      "1974\n",
      "1974 /home/disk/eos8/ach315/data/ISH/1974/723721-23184-1974\n",
      "1975\n",
      "1975 /home/disk/eos8/ach315/data/ISH/1975/723676-23048-1975\n",
      "1976\n",
      "1976 /home/disk/eos8/ach315/data/ISH/1976/722446-93987-1976\n",
      "1976 /home/disk/eos8/ach315/data/ISH/1976/724280-14821-1976\n",
      "1976 /home/disk/eos8/ach315/data/ISH/1976/912120-41415-1976\n",
      "1977\n",
      "1977 /home/disk/eos8/ach315/data/ISH/1977/724280-14821-1977\n",
      "1977 /home/disk/eos8/ach315/data/ISH/1977/726835-24230-1977\n",
      "1978\n",
      "1978 /home/disk/eos8/ach315/data/ISH/1978/723815-23161-1978\n",
      "1979\n",
      "1979 /home/disk/eos8/ach315/data/ISH/1979/723401-13963-1979\n",
      "1980\n",
      "1980 /home/disk/eos8/ach315/data/ISH/1980/723815-23161-1980\n",
      "1981\n",
      "1981 /home/disk/eos8/ach315/data/ISH/1981/723815-23161-1981\n",
      "1982\n",
      "1983\n",
      "1983 /home/disk/eos8/ach315/data/ISH/1983/726430-14920-1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n"
     ]
    }
   ],
   "source": [
    "count_start = datetime.datetime.now()\n",
    "\n",
    "# timing related settings\n",
    "years = np.arange(1961, 1991) # timeframe in which we have weather data\n",
    "#years = np.arange(1972,1975)\n",
    "dateparse = lambda dates: [pd.datetime.strptime(d, \"%Y%m%d%H\") for d in dates] # dateparsing method to be used in pd.read_fwf\n",
    "season_start, season_end = '03-01-', '11-30-' # setting a pretty borad range for growing season\n",
    "\n",
    "# setting up np.read_fwf arguments\n",
    "colnames = ['time', 'temp', 'dew_temp', 'precip', 'precip_time', 'precip_depth', 'precip_condition', 'precip_quality', 'rh']\n",
    "colspecs = [(15,25), (87,92), (93,98), (105,8193)]\n",
    "\n",
    "# empty dataframes to store data from all site-years\n",
    "df_temp_all = pd.DataFrame()\n",
    "df_rh_all = pd.DataFrame()\n",
    "df_precip_all = pd.DataFrame()\n",
    "\n",
    "# reading in all weather data and storing as dataframe\n",
    "for year in years:\n",
    "    print(year) # output to track code progress\n",
    "    times = pd.date_range(season_start + str(year), season_end + str(year), freq='1H')\n",
    "    fnames = glob.glob('/home/disk/eos8/ach315/data/ISH/' + str(year) + '/*')\n",
    "    \n",
    "    # creating dataframes to store all site data for an individual year\n",
    "    df_temp_sites = pd.DataFrame(index=times)\n",
    "    df_rh_sites = pd.DataFrame(index=times)\n",
    "    df_precip_sites = pd.DataFrame(index=times)\n",
    "    \n",
    "    for name in fnames:\n",
    "        # WBAN site name \n",
    "        site_id = name.split('/')[-1].split('-')[-2]\n",
    "        \n",
    "        # read in individual files\n",
    "        df = pd.read_fwf(name, names=colnames, colspecs=colspecs, header=None, index_col='time',\n",
    "                         encoding='latin_1', dtype={'temp':int, 'precip':str}, parse_dates=True, date_parser=dateparse)\n",
    "    \n",
    "        # remove duplicated hours, keeping only the first measurement per hour\n",
    "        df = df[df.index.duplicated(keep='first') == False]\n",
    "        \n",
    "        # add in missing time values (corrects for leap years) and keeps only growing season\n",
    "        df = df.reindex(times, fill_value=np.nan)\n",
    "        \n",
    "        # finding precip data\n",
    "        try:\n",
    "            df.precip_time = df[df['precip'].str.find('AA1')!=-1]['precip'].str.split('AA1').str.get(1).str.slice(0,2).astype(float)\n",
    "            df.precip_depth = df[df['precip'].str.find('AA1')!=-1]['precip'].str.split('AA1').str.get(1).str.slice(2, 6).astype(float)\n",
    "            df.precip_condition = df[df['precip'].str.find('AA1')!=-1]['precip'].str.split('AA1').str.get(1).str.slice(6,7).astype(float)\n",
    "            df.precip_quality = df[df['precip'].str.find('AA1')!=-1]['precip'].str.split('AA1').str.get(1).str.slice(7,8).astype(float)\n",
    "        except: \n",
    "            print(year, name)\n",
    "                \n",
    "        # replacing missing values (9999) with NANs \n",
    "        df.temp = df.temp.replace({9999: np.nan})\n",
    "        \n",
    "        # converting units \n",
    "        df.temp = df.temp/10\n",
    "        df.dew_temp = df.dew_temp/10\n",
    "        df.precip_depth = df.precip_depth/10\n",
    "        \n",
    "        # calculating RH through Clausius Clapeyron\n",
    "        df.rh = CC(df.temp, df.dew_temp)*100\n",
    "\n",
    "        # Combining weather data into individual dataframes\n",
    "        df_temp = pd.DataFrame({site_id: df.temp}, index= times)\n",
    "        df_rh = pd.DataFrame({site_id: df.rh}, index=times)\n",
    "        df_precip = pd.DataFrame({site_id: df.precip_depth}, index=times)\n",
    "        \n",
    "        df_temp_sites = pd.concat([df_temp_sites, df_temp], axis= 1, sort=True)\n",
    "        df_rh_sites = pd.concat([df_rh_sites, df_rh], axis=1, sort=True)\n",
    "        df_precip_sites = pd.concat([df_precip_sites, df_precip], axis=1, sort=True)\n",
    "\n",
    "    # combining all site-years data together\n",
    "    df_temp_all = pd.concat([df_temp_all, df_temp_sites], sort=True)\n",
    "    df_rh_all = pd.concat([df_rh_all, df_rh_sites], sort=True)\n",
    "    df_precip_all = pd.concat([df_precip_all, df_precip_sites], sort=True)\n",
    "\n",
    "count_end = datetime.datetime.now()\n",
    "diff = count_end - count_start\n",
    "print('run time:', diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1973 57 4045\n",
      "1973 100 2517\n",
      "1973 143 7699\n",
      "1974 49 7940\n",
      "1974 88 3446\n",
      "1974 139 8729\n",
      "1975 67 2010\n",
      "1975 83 9012\n",
      "1975 126 1354\n",
      "1976 32 3052\n",
      "1976 81 1936\n",
      "1976 172 4039\n",
      "1977 50 1440\n",
      "1977 86 2878\n",
      "1977 161 1561\n",
      "1977 168 2765\n",
      "1978 67 3720\n",
      "1979 61 7718\n",
      "1979 97 6485\n",
      "1979 102 1939\n",
      "1980 45 7102\n",
      "1980 64 6112\n",
      "1981 68 4417\n",
      "1981 68 5333\n",
      "1983 139 2230\n"
     ]
    }
   ],
   "source": [
    "# JH 191030: *** deprecated code, runs very slow\n",
    "#---- Reads in weather data from all years & sites, and compiles them into a large pd.DataFrame\n",
    "\n",
    "### Inputs for looping\n",
    "years = np.arange(1961,1991) #carefule with python indexing\n",
    "df_temp_all = pd.DataFrame() # Setting up an empty pd.DataFrame that will store all the information\n",
    "df_rh_all = pd.DataFrame()\n",
    "df_precip_all = pd.DataFrame()\n",
    "\n",
    "### Constants needed for RH calculation\n",
    "Es_Tref = 6.11 # saturation vapor pressure at reference temperature\n",
    "Tref = 273.15  # reference temperature\n",
    "Lv = 2.5e+06   # latent heat of vaporation (J/kg)\n",
    "Rv = 461       # gas constant for moist air (J/kg)\n",
    "\n",
    "### Clausius-Clapeyron \n",
    "# E = Es_Tref*np.exp((Lv/Rv)*(1/Tref - 1/Temp))*RH\n",
    "# if RH=1 E = Es\n",
    "# E: vapor pressure at Temp\n",
    "# Temp: air temperature (Kelvin)\n",
    "# RH: relative humidity\n",
    "\n",
    "\n",
    "### Begin the loop\n",
    "for i in years:    \n",
    "    file_list = pd.read_table(\"/home/disk/eos8/ach315/data/ISH/file_lists/file_list_\" + \n",
    "                              str(i) + \".csv\", squeeze = True, header = None)\n",
    "    timepoints = pd.date_range(start = str(i) + \"-01-01\", end = str(i) + \"-12-31 23:00:00\", freq = \"H\")\n",
    "    temp_dataframe = pd.DataFrame(index=timepoints)\n",
    "    rh_dataframe = pd.DataFrame(index=timepoints)\n",
    "    precip_dataframe = pd.DataFrame(index=timepoints)\n",
    "\n",
    "    \n",
    "    for j in range(0, len(file_list)):\n",
    "        weafile = pd.read_table(\"/home/disk/eos8/ach315/data/ISH/\" + str(i) + \n",
    "                                \"/\" + file_list[j], header = None, encoding=\"latin1\")\n",
    "        weadata = weafile.iloc[:,0]\n",
    "        WBAN_id = file_list[j][7:12] # WBAN site ID\n",
    "        year = file_list[j][13:17] # year\n",
    "        time = list()\n",
    "        temp = list()\n",
    "        temp_dew = list()\n",
    "        precip = list()\n",
    "        precip_hour = list()\n",
    "        \n",
    "        \n",
    "        for k in range(0, len(weadata)):\n",
    "            timestamp = pd.to_datetime(weadata[k][15:27], format=\"%Y%m%d%H%M\")\n",
    "            time.append(timestamp)\n",
    "        \n",
    "            if int(weadata[k][87:92]) == 9999:\n",
    "                temp.append(\"NaN\")\n",
    "            else:\n",
    "                temp.append(int(weadata[k][87:92])/10)\n",
    "            \n",
    "            if int(weadata[k][93:98]) == 9999:\n",
    "                temp_dew.append(\"NaN\")\n",
    "            else:\n",
    "                temp_dew.append(int(weadata[k][93:98])/10)\n",
    "            \n",
    "            precip_pos = weadata[k].find(\"AA1\")        \n",
    "            try: \n",
    "                if precip_pos == -1:\n",
    "                    precip.append(\"NaN\")\n",
    "                elif int(weadata[k][precip_pos+5:precip_pos+9]) == 9999:\n",
    "                    precip.append(\"NaN\")\n",
    "                else:\n",
    "                    precip.append(int(weadata[k][precip_pos+5:precip_pos+9]))\n",
    "            except:\n",
    "                precip.append(\"NaN\")\n",
    "                print(i, j, k)\n",
    "\n",
    "        Tair = np.array(temp, dtype = float) + 273\n",
    "        Tdew = np.array(temp_dew, dtype = float) + 273\n",
    "        es = Es_Tref*np.exp((Lv/Rv)*(1/Tref - 1/Tair))\n",
    "        e = Es_Tref*np.exp((Lv/Rv)*(1/Tref - 1/Tdew))\n",
    "        rh = e/es\n",
    "        rh = list(rh)\n",
    "        \n",
    "        temp_df = pd.DataFrame({WBAN_id: temp}, index= time)\n",
    "        temp_df = temp_df[~temp_df.index.duplicated()]\n",
    "        temp_dataframe = pd.concat([temp_dataframe, temp_df], axis= 1, \n",
    "                                   join_axes= [temp_dataframe.index])\n",
    "\n",
    "        rh_df = pd.DataFrame({WBAN_id: rh}, index=time)\n",
    "        rh_df = rh_df[~rh_df.index.duplicated()]\n",
    "        rh_dataframe = pd.concat([rh_dataframe, rh_df], axis= 1,\n",
    "                                 join_axes= [rh_dataframe.index])\n",
    "        \n",
    "        precip_df = pd.DataFrame({WBAN_id:precip}, index=time)\n",
    "        precip_df = precip_df[~precip_df.index.duplicated()]\n",
    "        precip_dataframe = pd.concat([precip_dataframe, precip_df], axis= 1,\n",
    "                                    join_axes= [precip_dataframe.index])\n",
    "        \n",
    "        \n",
    "    frames_temp = [df_temp_all, temp_dataframe]\n",
    "    df_temp_all = pd.concat(frames_temp)\n",
    "    \n",
    "    frames_rh = [df_rh_all, rh_dataframe]\n",
    "    df_rh_all = pd.concat(frames_rh)\n",
    "    \n",
    "    frames_precip = [df_precip_all, precip_dataframe]\n",
    "    df_precip_all = pd.concat(frames_precip)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Output the processed weather data into individual .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_all.to_csv(\"temp_all.csv\")\n",
    "df_precip_all.to_csv(\"precip_all.csv\")\n",
    "df_rh_all.to_csv(\"rh_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in and processing solrad data (NASA ISH_NSRD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: read in solar radiation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = pd.read_table(\"/home/disk/eos8/ach315/data/ISH_NSRD/file_list_1961to1990.txt\",\n",
    "                          header= None, squeeze= True)\n",
    "file_list = file_list[7096:]\n",
    "sites = pd.read_table(\"/home/disk/eos8/ach315/data/ISH_NSRD/station_list_1961to1990.txt\", \n",
    "                      header= None, squeeze= True, dtype= str)\n",
    "\n",
    "for i in file_list:    \n",
    "    solrad_file = pd.read_table(\"/home/disk/eos8/ach315/data/ISH_NSRD/1961to1990/\" + \n",
    "                                str(i), squeeze= True, header= None)\n",
    "    WBAN_id = i[0:5]\n",
    "    solrad_all = list()\n",
    "    timestamp_all = list()   \n",
    "        \n",
    "    for j in np.arange(1, len(solrad_file)):\n",
    "        solrad = solrad_file[j][23:27]\n",
    "        if solrad == 9999:\n",
    "            solrad_all.append(\"NaN\")\n",
    "        else:\n",
    "            solrad_all.append(solrad)\n",
    "        \n",
    "        year = \"19\" + solrad_file[j][1:3]\n",
    "        month = solrad_file[j][4:6]\n",
    "        day = solrad_file[j][7:9]\n",
    "        hour = solrad_file[j][10:12]\n",
    "        timestamp = dt.datetime(int(year), int(month), int(day), int(hour)-1) # hour must be in 0-23\n",
    "        timestamp = pd.to_datetime(timestamp)        \n",
    "        timestamp_all.append(timestamp)\n",
    "                    \n",
    "    df_solrad_all.loc[timestamp_all, WBAN_id] = solrad_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solrad_all.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JH 190216\n",
    "# Not sure why but all the last rows are 9999, and they were not converted into NaN\n",
    "# I double checkted that this only happens in the very last row, but wans't able to fix the code yet.\n",
    "# for not, here's a hot fix\n",
    "df_solrad_all.iloc[-1, :] = \"NaN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Output the processed solar radiation data into .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solrad_all.to_csv(\"solrad_all.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
